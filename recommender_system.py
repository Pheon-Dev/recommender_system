# -*- coding: utf-8 -*-
"""RECOMMENDER_SYSTEM (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XqEBkHpyo2vixZh3GzD_9L4FfcBxS2ne

## **RECOMMENDER SYSTEM FOR MOVIELENS DATASET**

***PHASE 4:GROUP 12 MEMBERS:***
1.   Daniel Wahome.
2.   Purity Gitonga.
3.   Brian Kariithi.
4.   Caroline Gesaka.
5.   James Njoroge.

# **INTRODUCTION**

In the era of digital content consumption, personalized recommendation systems play a crucial role in enhancing user experience and engagement. Leveraging the MovieLens dataset from the GroupLens research lab, we aim to build an effective movie recommendation system. This system will utilize collaborative filtering techniques to suggest movies based on user ratings, thereby providing personalized movie recommendations.

# **BUSINESS UNDERSTANDING**

The primary goal of this project is to enhance user satisfaction by recommending movies that align with their preferences. By analyzing user ratings and movie attributes, we aim to create a system that not only suggests popular or highly rated movies but also discovers niche interests that may not be immediately apparent.

## **PROBLEM STATEMENT**

Develop a recommendation system that provides top 5 movie recommendations to users based on their past ratings. The system should address the challenge of sparsity in user ratings and the cold start problem for new users.

## **OBJECTIVES**

**Build a Collaborative Filtering Model**: Implement a collaborative filtering model to recommend movies based on user ratings and similarities between users.


**Address the Cold Start Problem:** Explore methods to handle new users with limited or no historical data using techniques such as content-based filtering or hybrid approaches.


**Evaluate and Optimize:** Evaluate the performance of the recommendation system using appropriate metrics and optimize the model to improve recommendation accuracy and coverage.

## **DATA UNDERSTANDING**

### .***Dataset Source and Size:***

The dataset originates from MovieLens, provided by the GroupLens research lab at the University of Minnesota.

It includes a subset of ratings data, potentially from the "small" dataset version containing 100,000 ratings.

### .***Key Features***:
**movieId**: Unique identifier for each movie in the dataset.

**imdbId**: IMDb identifier for each movie.

**tmdbId**: The Movie Database (TMDb) identifier for each movie.

**userId_x**: Identifier for users who have rated movies.

**rating**: Rating given by a user to a movie (typically on a scale).

**timestamp_x**: Timestamp when a user rated a movie.

**title:** Title of the movie.

**genres**: Genres associated with each movie.

**userId_y:** Identifier for users who have tagged movies.

**tag**: Tags assigned by users to movies.

**timestamp_y**: Timestamp when a user tagged a movie.

## **Metrics of Success**

**Recommendation Accuracy**:
 Measure the accuracy of movie recommendations using metrics such as Precision@k and Recall@k.


**Coverage**:
 Ensure the system can recommend movies across a wide range of genres and user preferences.


**User Engagement:**
Monitor user engagement metrics, such as click-through rates on recommended movies, to assess the system's effectiveness in improving user interaction.

# . **DATA PREPARATION AND CLEANING**

import necessary libraries
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns
#pd.set_option('max_columns',20)
# !pip3 install scikit-surprise
import surprise
from surprise import Dataset, Reader, SVD, accuracy
from surprise.model_selection import train_test_split as surprise_train_test_split

"""load data"""

links = pd.read_csv(r'./content/links.csv')
ratings = pd.read_csv(r'./content/ratings.csv')
movies = pd.read_csv(r'./content/movies.csv')
tags = pd.read_csv(r'./content/tags.csv')

"""merge datasets on 'movieId' column"""

data1 = pd.merge(links, ratings, on='movieId', how="outer")
data2 = pd.merge(movies, tags, on='movieId',how="outer")
data  = pd.merge(data1, data2, on='movieId',how="outer")

"""explore data and its shape"""

data

"""the data has 285,783 rows and 11 columns, the column names are below"""

data.columns

data.describe()

data.info()

"""OBSERVATIONS

#### Handle missing values
"""

data.isnull().sum()

"""for columns in tmdbId, userId_x, rating, and timestamp_x will be filled in using imputer"""

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer

imputer = IterativeImputer()
missing_cols = ['userId_x', 'rating', 'timestamp_x']
data[missing_cols] = imputer.fit_transform(data[missing_cols])

#the above is used for continous data
#as 'tmdbId' is a identifier var mode shall be used

data['tmdbId'].fillna(data['tmdbId'].mode()[0], inplace=True)

data.isnull().sum()

# Fill missing values in tag column with a placeholder as we cant predict
#which tag will be associated, using measures of tendency may skew recommnedation
#because category and attached to another var 'movieId'
data['tag'].fillna(data['tag'].mode()[0], inplace=True)
data['userId_y'].fillna(method='ffill', inplace=True)
data['timestamp_y'].fillna(method='ffill', inplace=True)

#imputer option
# Handle 'tag' column separately since it's categorical
data['tag'].fillna('unknown', inplace=True)  # Or any other suitable placeholder

# Use IterativeImputer for numerical columns if needed
numerical_cols_with_missing = ['userId_y', 'timestamp_y']  # Or any other numerical columns
imputer = IterativeImputer()
data[numerical_cols_with_missing] = imputer.fit_transform(data[numerical_cols_with_missing])

data.isnull().sum()

data.duplicated().sum()

"""there are no duplicates"""

